{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4181f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 22:43:51.932243: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-27 22:43:51.932290: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-27 22:43:51.932311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-27 22:43:51.939229: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-27 22:43:52.687172: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from utils.utils_functions import *\n",
    "from utils.datasets import *\n",
    "import utils.config as config\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from models.registry import *\n",
    "from keras.callbacks import TensorBoard\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras import callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2faaa7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m      2\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mset_random_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_to_serializable\u001b[39m(obj):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif hasattr(obj, 'numpy'):\n",
    "        return float(obj.numpy())\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "os.makedirs('logs/architecture', exist_ok=True)\n",
    "os.makedirs('saved_models/testing_architecture', exist_ok=True)\n",
    "\n",
    "for model_name in MODELS_REGISTRY.keys():\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    log_dir = f'logs/architecture/{model_name}_experiment'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    model = MODELS_REGISTRY[model_name]()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(config.LR),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[\n",
    "            MeanIoUMetric(num_classes=3),\n",
    "            dice_coeff_metric()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"\\nBuilding datasets...\")\n",
    "    train_ds = build_dataset(\n",
    "        config.TRAIN_X,\n",
    "        config.TRAIN_Y,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        augment=True\n",
    "    )\n",
    "\n",
    "    val_ds = build_dataset(\n",
    "        config.VAL_X,\n",
    "        config.VAL_Y,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Training dataset batch size: {config.BATCH_SIZE}\")\n",
    "    print(f\"Validation dataset batch size: {config.BATCH_SIZE}\")\n",
    "\n",
    "    print(f\"\\nInitializing optimized dynamics logger...\")\n",
    "    dynamics_logger = OptimizedDynamicsLogger(\n",
    "        val_dataset=val_ds,\n",
    "        num_classes=3,\n",
    "        log_dir=log_dir,\n",
    "        max_samples=20,\n",
    "        batch_log_freq=1000\n",
    "    )\n",
    "    cbs = [\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath=f\"saved_models/testing_architecture/{model_name}_best.h5\",\n",
    "            monitor=\"val_mean_iou\",\n",
    "            mode=\"max\",\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor=\"val_mean_iou\",\n",
    "            mode=\"max\",\n",
    "            patience=6,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            update_freq=1000\n",
    "        ),\n",
    "        dynamics_logger\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=10,\n",
    "            callbacks=cbs,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"Training completed successfully!\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        history_path = f\"saved_models/testing_architecture/{model_name}_history.json\"\n",
    "        print(f\"\\nSaving training history to {history_path}...\")\n",
    "        with open(history_path, \"w\") as f:\n",
    "            serializable_history = convert_to_serializable(history.history)\n",
    "            json.dump(serializable_history, f, indent=2)\n",
    "\n",
    "        dyn_path = f\"saved_models/testing_architecture/{model_name}_dynamics.json\"\n",
    "        print(f\"Exporting dynamics to {dyn_path}...\")\n",
    "        dynamics_logger.export_to_json(dyn_path)\n",
    "\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\"TRAINING SUMMARY\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Best val_loss: {min(history.history['val_loss']):.4f}\")\n",
    "        if 'mean_iou' in history.history:\n",
    "            print(f\"Best val_mean_iou: {max(history.history.get('val_mean_iou', [0])):.4f}\")\n",
    "        print(f\"\\nFiles saved:\")\n",
    "        print(f\"  - Model: saved_models/testing_architecture/{model_name}_best.h5\")\n",
    "        print(f\"  - History: {history_path}\")\n",
    "        print(f\"  - Dynamics: {dyn_path}\")\n",
    "        print(f\"  - Logs: {log_dir}\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n{'!'*70}\")\n",
    "        print(f\"ERROR during training with {model_name}!\")\n",
    "        print(f\"{'!'*70}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    finally:\n",
    "        print(\"\\nCleaning up memory...\")\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL EXPERIMENTS COMPLETED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTo view all results in TensorBoard:\")\n",
    "print(\"  tensorboard --logdir=logs/architecture/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1415dda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m MODELS_REGISTRY\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "for model_name in MODELS_REGISTRY.keys():\n",
    "    model = load_model(\n",
    "        f\"saved_models/testing_architecture/{model_name}_best.h5\",\n",
    "        compile=False\n",
    "    )\n",
    "\n",
    "    tf.keras.utils.plot_model(\n",
    "        model,\n",
    "        to_file=f\"saved_models/{model_name}_architecture.png\",\n",
    "        show_shapes=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

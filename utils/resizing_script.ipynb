{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ff5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "\n",
      "Processing train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2975/2975 [10:29<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 2975 images from train split\n",
      "Failed: 0\n",
      "\n",
      "Processing val split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 500/500 [01:48<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 500 images from val split\n",
      "Failed: 0\n",
      "\n",
      "Processing test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 1525/1525 [05:15<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 1525 images from test split\n",
      "Failed: 0\n",
      "\n",
      "==================================================\n",
      "Preprocessing complete!\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "HUMAN_CLASSES = {24, 25}\n",
    "VEHICLE_CLASSES = {26, 27, 28, 31, 32, 33}  \n",
    "\n",
    "class CityscapesPreprocessor:\n",
    "    def __init__(self, input_root, output_root, scale_factor=0.25):\n",
    "        self.input_root = Path(input_root)\n",
    "        self.output_root = Path(output_root)\n",
    "        self.scale_factor = scale_factor\n",
    "        \n",
    "    def process_all_splits(self):\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            print(f\"\\nProcessing {split} split...\")\n",
    "            self.process_split(split)\n",
    "    \n",
    "    def process_split(self, split):\n",
    "        img_dir = self.input_root / 'leftImg8bit' / split\n",
    "        gt_dir = self.input_root / 'gtFine' / split\n",
    "        \n",
    "        out_img_dir = self.output_root / split / 'images'\n",
    "        out_mask_dir = self.output_root / split / 'masks'\n",
    "        out_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_mask_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        image_files = []\n",
    "\n",
    "        for city_dir in sorted(img_dir.iterdir()):\n",
    "            if not city_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "            for img_file in sorted(city_dir.glob('*_leftImg8bit.png')):\n",
    "                base = img_file.stem.replace('_leftImg8bit', '')\n",
    "                gt_city = gt_dir / city_dir.name\n",
    "                instance_file = gt_city / f\"{base}_gtFine_instanceIds.png\"\n",
    "\n",
    "                if instance_file.exists():\n",
    "                    image_files.append((img_file, instance_file, base))\n",
    "\n",
    "        saved_count = 0\n",
    "        failed_count = 0\n",
    "        for img_path, inst_path, base_name in tqdm(image_files, desc=f\"{split}\"):\n",
    "            out_img_path = out_img_dir / f\"{base_name}.png\"\n",
    "            out_mask_path = out_mask_dir / f\"{base_name}.npy\"\n",
    "            \n",
    "            if self._process_single_image(\n",
    "                img_path, inst_path, base_name, out_img_dir, out_mask_dir\n",
    "            ):\n",
    "                if out_img_path.exists() and out_mask_path.exists():\n",
    "                    try:\n",
    "                        Image.open(out_img_path).load()\n",
    "                        np.load(out_mask_path)\n",
    "                        saved_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Verification failed for {base_name}: {e}\")\n",
    "                        out_img_path.unlink(missing_ok=True)\n",
    "                        out_mask_path.unlink(missing_ok=True)\n",
    "                        failed_count += 1\n",
    "            else:\n",
    "                failed_count += 1\n",
    "\n",
    "        print(f\"Successfully saved {saved_count} images from {split} split\")\n",
    "        print(f\"Failed: {failed_count}\")\n",
    "\n",
    "    def _process_single_image(self, img_path, inst_path, base_name, out_img_dir, out_mask_dir):\n",
    "        try:\n",
    "            image = np.array(Image.open(img_path))\n",
    "            instances = np.array(Image.open(inst_path))\n",
    "            \n",
    "            new_height = int(image.shape[0] * self.scale_factor)\n",
    "            new_width = int(image.shape[1] * self.scale_factor)\n",
    "            resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "            resized_instances = cv2.resize(instances, (new_width, new_height), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            combined_mask = self._create_combined_mask(resized_instances)\n",
    "            \n",
    "            out_img = Image.fromarray(resized_image)\n",
    "            out_img.save(out_img_dir / f\"{base_name}.png\", optimize=False)\n",
    "            out_img.close()\n",
    "            \n",
    "            np.save(out_mask_dir / f\"{base_name}.npy\", combined_mask)\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {base_name}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _create_combined_mask(self, instances):\n",
    "        \"\"\"\n",
    "        Output encoding:\n",
    "        0                = background\n",
    "        1000 + k         = human instance k\n",
    "        2000 + k         = vehicle instance k\n",
    "        \"\"\"\n",
    "        new_mask = np.zeros_like(instances, dtype=np.int32)\n",
    "\n",
    "        human_instance_counter = 1\n",
    "        vehicle_instance_counter = 1\n",
    "\n",
    "        unique_ids = np.unique(instances)\n",
    "\n",
    "        for inst_id in unique_ids:\n",
    "            if inst_id < 1000:\n",
    "                continue\n",
    "\n",
    "            class_id = inst_id // 1000\n",
    "\n",
    "            # Humans\n",
    "            if class_id in {24, 25}:\n",
    "                new_mask[instances == inst_id] = 1000 + human_instance_counter\n",
    "                human_instance_counter += 1\n",
    "\n",
    "            # Vehicles\n",
    "            elif class_id in {26, 27, 28, 31, 32, 33}:\n",
    "                new_mask[instances == inst_id] = 2000 + vehicle_instance_counter\n",
    "                vehicle_instance_counter += 1\n",
    "\n",
    "        return new_mask\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starting preprocessing...\")\n",
    "preprocessor = CityscapesPreprocessor(\n",
    "    input_root='original_dataset/',\n",
    "    output_root='processed_dataset/',\n",
    "    scale_factor=0.25\n",
    ")\n",
    "preprocessor.process_all_splits()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Preprocessing complete!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4471e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 01:03:44.103088: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-28 01:03:44.103168: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-28 01:03:44.103196: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-28 01:03:44.113271: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-28 01:03:45.325976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from utils.utils_functions import *\n",
    "from utils.datasets import *\n",
    "import utils.config as config\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from models.registry import *\n",
    "from keras.callbacks import TensorBoard\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras import callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bb49f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================================================================\n",
      "Training model3\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 01:03:49.715672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-28 01:03:49.755263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-28 01:03:49.755320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-28 01:03:49.758582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-28 01:03:49.758638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-28 01:03:49.758668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-28 01:03:50.038620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-28 01:03:50.038687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-28 01:03:50.038695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2026-01-28 01:03:50.038742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-28 01:03:50.038761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4084 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building datasets...\n",
      "Training dataset batch size: 2\n",
      "Validation dataset batch size: 2\n",
      "\n",
      "Initializing optimized dynamics logger...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 01:03:58.191917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2026-01-28 01:03:59.019774: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-28 01:04:00.534765: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0c2575c0a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-01-28 01:04:00.534808: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660, Compute Capability 7.5\n",
      "2026-01-28 01:04:00.543774: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-28 01:04:00.651568: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2026-01-28 01:04:01.523938: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-28 01:04:05.258894: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-28 01:04:05.258958: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-28 01:04:05.276252: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/1488 [..............................] - ETA: 5:37 - loss: 1.0552 - mean_iou: 0.3027 - dice_coeff: 0.2089WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0985s vs `on_train_batch_end` time: 0.2166s). Check your callbacks.\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 0.2208 - mean_iou: 0.4031 - dice_coeff: 0.2822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 01:09:43.957539: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1488/1488 [==============================] - ETA: 0s - loss: 0.2208 - mean_iou: 0.4031 - dice_coeff: 0.2822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 01:09:46.478278: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-28 01:09:46.478347: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-28 01:09:46.490071: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_mean_iou improved from -inf to 0.41378, saving model to saved_models/final_model/model3_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/miniconda3/envs/tf_env/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1424 | Mean IoU: 0.4285\n",
      "1488/1488 [==============================] - 378s 244ms/step - loss: 0.2208 - mean_iou: 0.4031 - dice_coeff: 0.2822 - val_loss: 0.1777 - val_mean_iou: 0.4138 - val_dice_coeff: 0.2859 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.1352 - mean_iou: 0.5207 - dice_coeff: 0.2986\n",
      "Epoch 2: val_mean_iou improved from 0.41378 to 0.55673, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1304 | Mean IoU: 0.5123\n",
      "1488/1488 [==============================] - 363s 242ms/step - loss: 0.1352 - mean_iou: 0.5207 - dice_coeff: 0.2986 - val_loss: 0.1393 - val_mean_iou: 0.5567 - val_dice_coeff: 0.2981 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.1064 - mean_iou: 0.6124 - dice_coeff: 0.3047\n",
      "Epoch 3: val_mean_iou improved from 0.55673 to 0.60789, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1326 | Mean IoU: 0.5760\n",
      "1488/1488 [==============================] - 362s 241ms/step - loss: 0.1064 - mean_iou: 0.6124 - dice_coeff: 0.3047 - val_loss: 0.1052 - val_mean_iou: 0.6079 - val_dice_coeff: 0.3056 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0915 - mean_iou: 0.6541 - dice_coeff: 0.3080\n",
      "Epoch 4: val_mean_iou improved from 0.60789 to 0.64469, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1115 | Mean IoU: 0.5959\n",
      "1488/1488 [==============================] - 355s 237ms/step - loss: 0.0915 - mean_iou: 0.6541 - dice_coeff: 0.3080 - val_loss: 0.0987 - val_mean_iou: 0.6447 - val_dice_coeff: 0.3074 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0809 - mean_iou: 0.6830 - dice_coeff: 0.3102\n",
      "Epoch 5: val_mean_iou did not improve from 0.64469\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1096 | Mean IoU: 0.6057\n",
      "1488/1488 [==============================] - 348s 231ms/step - loss: 0.0809 - mean_iou: 0.6830 - dice_coeff: 0.3102 - val_loss: 0.1091 - val_mean_iou: 0.6425 - val_dice_coeff: 0.3116 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0759 - mean_iou: 0.6996 - dice_coeff: 0.3112\n",
      "Epoch 6: val_mean_iou improved from 0.64469 to 0.68055, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1004 | Mean IoU: 0.6259\n",
      "1488/1488 [==============================] - 348s 231ms/step - loss: 0.0759 - mean_iou: 0.6996 - dice_coeff: 0.3112 - val_loss: 0.0871 - val_mean_iou: 0.6805 - val_dice_coeff: 0.3116 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0696 - mean_iou: 0.7181 - dice_coeff: 0.3126\n",
      "Epoch 7: val_mean_iou improved from 0.68055 to 0.70276, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0759 | Mean IoU: 0.6875\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0696 - mean_iou: 0.7181 - dice_coeff: 0.3126 - val_loss: 0.0756 - val_mean_iou: 0.7028 - val_dice_coeff: 0.3115 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0633 - mean_iou: 0.7396 - dice_coeff: 0.3140\n",
      "Epoch 8: val_mean_iou did not improve from 0.70276\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0806 | Mean IoU: 0.6711\n",
      "1488/1488 [==============================] - 347s 231ms/step - loss: 0.0633 - mean_iou: 0.7396 - dice_coeff: 0.3140 - val_loss: 0.0743 - val_mean_iou: 0.6999 - val_dice_coeff: 0.3112 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0611 - mean_iou: 0.7494 - dice_coeff: 0.3146\n",
      "Epoch 9: val_mean_iou improved from 0.70276 to 0.71111, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0761 | Mean IoU: 0.6892\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0611 - mean_iou: 0.7494 - dice_coeff: 0.3146 - val_loss: 0.0706 - val_mean_iou: 0.7111 - val_dice_coeff: 0.3132 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0574 - mean_iou: 0.7612 - dice_coeff: 0.3154\n",
      "Epoch 10: val_mean_iou improved from 0.71111 to 0.72302, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0766 | Mean IoU: 0.7116\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0574 - mean_iou: 0.7612 - dice_coeff: 0.3154 - val_loss: 0.0680 - val_mean_iou: 0.7230 - val_dice_coeff: 0.3145 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0522 - mean_iou: 0.7768 - dice_coeff: 0.3164\n",
      "Epoch 11: val_mean_iou improved from 0.72302 to 0.74710, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0616 | Mean IoU: 0.7253\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0522 - mean_iou: 0.7768 - dice_coeff: 0.3164 - val_loss: 0.0647 - val_mean_iou: 0.7471 - val_dice_coeff: 0.3165 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0507 - mean_iou: 0.7822 - dice_coeff: 0.3168\n",
      "Epoch 12: val_mean_iou did not improve from 0.74710\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0508 | Mean IoU: 0.7493\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0507 - mean_iou: 0.7822 - dice_coeff: 0.3168 - val_loss: 0.0641 - val_mean_iou: 0.7468 - val_dice_coeff: 0.3140 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0470 - mean_iou: 0.7947 - dice_coeff: 0.3176\n",
      "Epoch 13: val_mean_iou did not improve from 0.74710\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0570 | Mean IoU: 0.7312\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0470 - mean_iou: 0.7947 - dice_coeff: 0.3176 - val_loss: 0.0671 - val_mean_iou: 0.7393 - val_dice_coeff: 0.3161 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0444 - mean_iou: 0.8031 - dice_coeff: 0.3182\n",
      "Epoch 14: val_mean_iou improved from 0.74710 to 0.75878, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0568 | Mean IoU: 0.7369\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0444 - mean_iou: 0.8031 - dice_coeff: 0.3182 - val_loss: 0.0607 - val_mean_iou: 0.7588 - val_dice_coeff: 0.3175 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0426 - mean_iou: 0.8090 - dice_coeff: 0.3187\n",
      "Epoch 15: val_mean_iou did not improve from 0.75878\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0888 | Mean IoU: 0.6931\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0426 - mean_iou: 0.8090 - dice_coeff: 0.3187 - val_loss: 0.0631 - val_mean_iou: 0.7551 - val_dice_coeff: 0.3178 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0404 - mean_iou: 0.8182 - dice_coeff: 0.3193\n",
      "Epoch 16: val_mean_iou improved from 0.75878 to 0.76270, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0512 | Mean IoU: 0.7374\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0404 - mean_iou: 0.8182 - dice_coeff: 0.3193 - val_loss: 0.0619 - val_mean_iou: 0.7627 - val_dice_coeff: 0.3179 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0373 - mean_iou: 0.8268 - dice_coeff: 0.3199\n",
      "Epoch 17: val_mean_iou did not improve from 0.76270\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "  LR: 5.00e-05 | Class IoU Var: 0.0905 | Mean IoU: 0.6966\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0373 - mean_iou: 0.8268 - dice_coeff: 0.3199 - val_loss: 0.0632 - val_mean_iou: 0.7572 - val_dice_coeff: 0.3174 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0324 - mean_iou: 0.8453 - dice_coeff: 0.3211\n",
      "Epoch 18: val_mean_iou improved from 0.76270 to 0.78262, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 5.00e-05 | Class IoU Var: 0.0561 | Mean IoU: 0.7518\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0324 - mean_iou: 0.8453 - dice_coeff: 0.3211 - val_loss: 0.0552 - val_mean_iou: 0.7826 - val_dice_coeff: 0.3185 - lr: 5.0000e-05\n",
      "Epoch 19/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0306 - mean_iou: 0.8519 - dice_coeff: 0.3216\n",
      "Epoch 19: val_mean_iou improved from 0.78262 to 0.78521, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 5.00e-05 | Class IoU Var: 0.0439 | Mean IoU: 0.7704\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0306 - mean_iou: 0.8519 - dice_coeff: 0.3216 - val_loss: 0.0553 - val_mean_iou: 0.7852 - val_dice_coeff: 0.3188 - lr: 5.0000e-05\n",
      "Epoch 20/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0298 - mean_iou: 0.8551 - dice_coeff: 0.3218\n",
      "Epoch 20: val_mean_iou improved from 0.78521 to 0.78677, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 5.00e-05 | Class IoU Var: 0.0485 | Mean IoU: 0.7630\n",
      "1488/1488 [==============================] - 347s 231ms/step - loss: 0.0298 - mean_iou: 0.8551 - dice_coeff: 0.3218 - val_loss: 0.0563 - val_mean_iou: 0.7868 - val_dice_coeff: 0.3192 - lr: 5.0000e-05\n",
      "Epoch 21/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0290 - mean_iou: 0.8589 - dice_coeff: 0.3220\n",
      "Epoch 21: val_mean_iou improved from 0.78677 to 0.79028, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "  LR: 2.50e-05 | Class IoU Var: 0.0471 | Mean IoU: 0.7649\n",
      "1488/1488 [==============================] - 349s 232ms/step - loss: 0.0290 - mean_iou: 0.8589 - dice_coeff: 0.3220 - val_loss: 0.0563 - val_mean_iou: 0.7903 - val_dice_coeff: 0.3197 - lr: 5.0000e-05\n",
      "Epoch 22/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0265 - mean_iou: 0.8684 - dice_coeff: 0.3227\n",
      "Epoch 22: val_mean_iou improved from 0.79028 to 0.79064, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 2.50e-05 | Class IoU Var: 0.0371 | Mean IoU: 0.7859\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0265 - mean_iou: 0.8684 - dice_coeff: 0.3227 - val_loss: 0.0578 - val_mean_iou: 0.7906 - val_dice_coeff: 0.3195 - lr: 2.5000e-05\n",
      "Epoch 23/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0257 - mean_iou: 0.8714 - dice_coeff: 0.3229\n",
      "Epoch 23: val_mean_iou did not improve from 0.79064\n",
      "\n",
      "  LR: 2.50e-05 | Class IoU Var: 0.0570 | Mean IoU: 0.7438\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0257 - mean_iou: 0.8714 - dice_coeff: 0.3229 - val_loss: 0.0590 - val_mean_iou: 0.7889 - val_dice_coeff: 0.3192 - lr: 2.5000e-05\n",
      "Epoch 24/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0252 - mean_iou: 0.8738 - dice_coeff: 0.3231\n",
      "Epoch 24: val_mean_iou improved from 0.79064 to 0.79142, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "  LR: 1.25e-05 | Class IoU Var: 0.0441 | Mean IoU: 0.7710\n",
      "1488/1488 [==============================] - 348s 231ms/step - loss: 0.0252 - mean_iou: 0.8738 - dice_coeff: 0.3231 - val_loss: 0.0575 - val_mean_iou: 0.7914 - val_dice_coeff: 0.3198 - lr: 2.5000e-05\n",
      "Epoch 25/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0240 - mean_iou: 0.8789 - dice_coeff: 0.3234\n",
      "Epoch 25: val_mean_iou improved from 0.79142 to 0.79302, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 1.25e-05 | Class IoU Var: 0.0458 | Mean IoU: 0.7685\n",
      "1488/1488 [==============================] - 349s 232ms/step - loss: 0.0240 - mean_iou: 0.8789 - dice_coeff: 0.3234 - val_loss: 0.0582 - val_mean_iou: 0.7930 - val_dice_coeff: 0.3201 - lr: 1.2500e-05\n",
      "Epoch 26/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0237 - mean_iou: 0.8804 - dice_coeff: 0.3235\n",
      "Epoch 26: val_mean_iou did not improve from 0.79302\n",
      "\n",
      "  LR: 1.25e-05 | Class IoU Var: 0.0435 | Mean IoU: 0.7716\n",
      "1488/1488 [==============================] - 348s 231ms/step - loss: 0.0237 - mean_iou: 0.8804 - dice_coeff: 0.3235 - val_loss: 0.0602 - val_mean_iou: 0.7904 - val_dice_coeff: 0.3197 - lr: 1.2500e-05\n",
      "Epoch 27/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0231 - mean_iou: 0.8825 - dice_coeff: 0.3237\n",
      "Epoch 27: val_mean_iou did not improve from 0.79302\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "  LR: 6.25e-06 | Class IoU Var: 0.0483 | Mean IoU: 0.7622\n",
      "1488/1488 [==============================] - 348s 232ms/step - loss: 0.0231 - mean_iou: 0.8825 - dice_coeff: 0.3237 - val_loss: 0.0617 - val_mean_iou: 0.7874 - val_dice_coeff: 0.3195 - lr: 1.2500e-05\n",
      "Epoch 28/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0229 - mean_iou: 0.8838 - dice_coeff: 0.3237\n",
      "Epoch 28: val_mean_iou improved from 0.79302 to 0.79338, saving model to saved_models/final_model/model3_best.h5\n",
      "\n",
      "  LR: 6.25e-06 | Class IoU Var: 0.0472 | Mean IoU: 0.7653\n",
      "1488/1488 [==============================] - 351s 231ms/step - loss: 0.0229 - mean_iou: 0.8838 - dice_coeff: 0.3237 - val_loss: 0.0607 - val_mean_iou: 0.7934 - val_dice_coeff: 0.3201 - lr: 6.2500e-06\n",
      "Epoch 29/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0225 - mean_iou: 0.8846 - dice_coeff: 0.3238\n",
      "Epoch 29: val_mean_iou did not improve from 0.79338\n",
      "\n",
      "  LR: 6.25e-06 | Class IoU Var: 0.0462 | Mean IoU: 0.7680\n",
      "1488/1488 [==============================] - 348s 231ms/step - loss: 0.0225 - mean_iou: 0.8846 - dice_coeff: 0.3238 - val_loss: 0.0609 - val_mean_iou: 0.7932 - val_dice_coeff: 0.3203 - lr: 6.2500e-06\n",
      "Epoch 30/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0221 - mean_iou: 0.8865 - dice_coeff: 0.3239\n",
      "Epoch 30: val_mean_iou did not improve from 0.79338\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "  LR: 3.12e-06 | Class IoU Var: 0.0427 | Mean IoU: 0.7733\n",
      "1488/1488 [==============================] - 348s 231ms/step - loss: 0.0221 - mean_iou: 0.8865 - dice_coeff: 0.3239 - val_loss: 0.0629 - val_mean_iou: 0.7914 - val_dice_coeff: 0.3198 - lr: 6.2500e-06\n",
      "Epoch 31/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0220 - mean_iou: 0.8874 - dice_coeff: 0.3240\n",
      "Epoch 31: val_mean_iou did not improve from 0.79338\n",
      "\n",
      "  LR: 3.12e-06 | Class IoU Var: 0.0434 | Mean IoU: 0.7722\n",
      "1488/1488 [==============================] - 348s 231ms/step - loss: 0.0220 - mean_iou: 0.8874 - dice_coeff: 0.3240 - val_loss: 0.0622 - val_mean_iou: 0.7927 - val_dice_coeff: 0.3201 - lr: 3.1250e-06\n",
      "Epoch 32/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0220 - mean_iou: 0.8877 - dice_coeff: 0.3240\n",
      "Epoch 32: val_mean_iou did not improve from 0.79338\n",
      "\n",
      "  LR: 3.12e-06 | Class IoU Var: 0.0464 | Mean IoU: 0.7664\n",
      "1488/1488 [==============================] - 347s 231ms/step - loss: 0.0220 - mean_iou: 0.8877 - dice_coeff: 0.3240 - val_loss: 0.0625 - val_mean_iou: 0.7917 - val_dice_coeff: 0.3200 - lr: 3.1250e-06\n",
      "Epoch 33/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0220 - mean_iou: 0.8877 - dice_coeff: 0.3240\n",
      "Epoch 33: val_mean_iou did not improve from 0.79338\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "  LR: 1.56e-06 | Class IoU Var: 0.0444 | Mean IoU: 0.7700\n",
      "1488/1488 [==============================] - 379s 250ms/step - loss: 0.0220 - mean_iou: 0.8877 - dice_coeff: 0.3240 - val_loss: 0.0620 - val_mean_iou: 0.7914 - val_dice_coeff: 0.3199 - lr: 3.1250e-06\n",
      "Epoch 34/50\n",
      "1488/1488 [==============================] - ETA: 0s - loss: 0.0219 - mean_iou: 0.8880 - dice_coeff: 0.3240\n",
      "Epoch 34: val_mean_iou did not improve from 0.79338\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "\n",
      "  LR: 1.56e-06 | Class IoU Var: 0.0472 | Mean IoU: 0.7653\n",
      "1488/1488 [==============================] - 351s 231ms/step - loss: 0.0219 - mean_iou: 0.8880 - dice_coeff: 0.3240 - val_loss: 0.0628 - val_mean_iou: 0.7919 - val_dice_coeff: 0.3199 - lr: 1.5625e-06\n",
      "Epoch 34: early stopping\n",
      "\n",
      "======================================================================\n",
      "Training completed successfully!\n",
      "======================================================================\n",
      "\n",
      "Saving training history to saved_models/final_model/model3_history.json...\n",
      "Exporting dynamics to saved_models/final_model/model3_dynamics.json...\n",
      "Metrics exported to saved_models/final_model/model3_dynamics.json\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING SUMMARY\n",
      "----------------------------------------------------------------------\n",
      "Model: model3\n",
      "Best val_loss: 0.0552\n",
      "Best val_mean_iou: 0.7934\n",
      "\n",
      "Files saved:\n",
      "  - Model: saved_models/final_model/model3_best.h5\n",
      "  - History: saved_models/final_model/model3_history.json\n",
      "  - Dynamics: saved_models/final_model/model3_dynamics.json\n",
      "  - Logs: logs/final_model/model3_experiment\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Cleaning up memory...\n",
      "\n",
      "======================================================================\n",
      "ALL EXPERIMENTS COMPLETED\n",
      "======================================================================\n",
      "\n",
      "To view all results in TensorBoard:\n",
      "  tensorboard --logdir=logs/final_model/\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif hasattr(obj, 'numpy'):\n",
    "        return float(obj.numpy())\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "os.makedirs('logs/final_model', exist_ok=True)\n",
    "os.makedirs('saved_models/final_model', exist_ok=True)\n",
    "\n",
    "for model_name in MODELS_REGISTRY.keys():\n",
    "    if model_name!='model3':\n",
    "        continue\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Create log directory for this experiment\n",
    "    log_dir = f'logs/final_model/{model_name}_experiment'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    model = MODELS_REGISTRY[model_name]()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(config.LR),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[\n",
    "            MeanIoUMetric(num_classes=3),\n",
    "            dice_coeff_metric()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Build datasets\n",
    "    print(\"\\nBuilding datasets...\")\n",
    "    train_ds = build_dataset(\n",
    "        config.TRAIN_X,\n",
    "        config.TRAIN_Y,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        augment=True\n",
    "    )\n",
    "\n",
    "    val_ds = build_dataset(\n",
    "        config.VAL_X,\n",
    "        config.VAL_Y,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Training dataset batch size: {config.BATCH_SIZE}\")\n",
    "    print(f\"Validation dataset batch size: {config.BATCH_SIZE}\")\n",
    "\n",
    "    # FIXED: Create optimized logger with memory-safe settings\n",
    "    print(f\"\\nInitializing optimized dynamics logger...\")\n",
    "    dynamics_logger = OptimizedDynamicsLogger(\n",
    "        val_dataset=val_ds,\n",
    "        num_classes=3,\n",
    "        log_dir=log_dir,\n",
    "        max_samples=20,\n",
    "        batch_log_freq=3000\n",
    "    )\n",
    "    cbs = [\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath=f\"saved_models/final_model/{model_name}_best.h5\",\n",
    "            monitor=\"val_mean_iou\",  # ✓ Changed to IoU\n",
    "            mode=\"max\",              # ✓ Higher is better\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor=\"val_mean_iou\",  # ✓ Changed to IoU\n",
    "            mode=\"max\",              # ✓ Higher is better\n",
    "            patience=6,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            update_freq=1000\n",
    "        ),\n",
    "        dynamics_logger\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=50,\n",
    "            callbacks=cbs,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"Training completed successfully!\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        history_path = f\"saved_models/final_model/{model_name}_history.json\"\n",
    "        print(f\"\\nSaving training history to {history_path}...\")\n",
    "        with open(history_path, \"w\") as f:\n",
    "            serializable_history = convert_to_serializable(history.history)\n",
    "            json.dump(serializable_history, f, indent=2)\n",
    "\n",
    "        dyn_path = f\"saved_models/final_model/{model_name}_dynamics.json\"\n",
    "        print(f\"Exporting dynamics to {dyn_path}...\")\n",
    "        dynamics_logger.export_to_json(dyn_path)\n",
    "\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\"TRAINING SUMMARY\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Best val_loss: {min(history.history['val_loss']):.4f}\")\n",
    "        if 'mean_iou' in history.history:\n",
    "            print(f\"Best val_mean_iou: {max(history.history.get('val_mean_iou', [0])):.4f}\")\n",
    "        print(f\"\\nFiles saved:\")\n",
    "        print(f\"  - Model: saved_models/final_model/{model_name}_best.h5\")\n",
    "        print(f\"  - History: {history_path}\")\n",
    "        print(f\"  - Dynamics: {dyn_path}\")\n",
    "        print(f\"  - Logs: {log_dir}\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n{'!'*70}\")\n",
    "        print(f\"ERROR during training with {model_name}!\")\n",
    "        print(f\"{'!'*70}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    finally:\n",
    "        print(\"\\nCleaning up memory...\")\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL EXPERIMENTS COMPLETED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTo view all results in TensorBoard:\")\n",
    "print(\"  tensorboard --logdir=logs/final_model/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391dd3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 13:10:20.943198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-27 13:10:20.943252: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-27 13:10:20.943271: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-27 13:10:20.948327: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-27 13:10:21.702926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "import os\n",
    "from utils.utils_functions import *\n",
    "import json\n",
    "import numpy as np\n",
    "from models.registry import MODELS_REGISTRY\n",
    "from utils.datasets import build_dataset\n",
    "import utils.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b914098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================================================================\n",
      "Training model1 with loss: sparse_cce\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 13:10:22.712481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-27 13:10:22.741315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-27 13:10:22.741385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-27 13:10:22.743820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-27 13:10:22.743887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-27 13:10:22.743936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-27 13:10:22.929339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-27 13:10:22.929394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-27 13:10:22.929401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2026-01-27 13:10:22.929439: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-27 13:10:22.929454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4084 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building datasets...\n",
      "Training dataset batch size: 1\n",
      "Validation dataset batch size: 1\n",
      "\n",
      "Initializing optimized dynamics logger...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 13:10:26.913432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2026-01-27 13:10:29.164444: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f38f77f4a90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-01-27 13:10:29.164492: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660, Compute Capability 7.5\n",
      "2026-01-27 13:10:29.169238: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-27 13:10:29.248047: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2026-01-27 13:10:33.653197: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-27 13:10:33.653256: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/200 [..............................] - ETA: 43s - loss: 1.0754 - mean_iou: 0.2620 - dice_coeff: 0.2001WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0927s vs `on_train_batch_end` time: 0.2071s). Check your callbacks.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3516 - mean_iou: 0.3061 - dice_coeff: 0.2622\n",
      "Epoch 1: val_mean_iou improved from -inf to 0.30931, saving model to loss_experiments/model1_sparse_cce_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/miniconda3/envs/tf_env/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2026-01-27 13:11:24.013418: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1132462080 exceeds 10% of free system memory.\n",
      "2026-01-27 13:11:24.361229: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2264924160 exceeds 10% of free system memory.\n",
      "2026-01-27 13:11:24.950583: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1698693120 exceeds 10% of free system memory.\n",
      "2026-01-27 13:11:26.919709: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1726 | Mean IoU: 0.2938\n",
      "200/200 [==============================] - 64s 263ms/step - loss: 0.3516 - mean_iou: 0.3061 - dice_coeff: 0.2622 - val_loss: 0.2617 - val_mean_iou: 0.3093 - val_dice_coeff: 0.2728 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2430 - mean_iou: 0.3074 - dice_coeff: 0.2730\n",
      "Epoch 2: val_mean_iou did not improve from 0.30931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 13:12:14.945836: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1132462080 exceeds 10% of free system memory.\n",
      "2026-01-27 13:12:15.308210: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2264924160 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1726 | Mean IoU: 0.2938\n",
      "200/200 [==============================] - 49s 242ms/step - loss: 0.2430 - mean_iou: 0.3074 - dice_coeff: 0.2730 - val_loss: 0.2264 - val_mean_iou: 0.3093 - val_dice_coeff: 0.2730 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1990 - mean_iou: 0.3528 - dice_coeff: 0.2798\n",
      "Epoch 3: val_mean_iou improved from 0.30931 to 0.39235, saving model to loss_experiments/model1_sparse_cce_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1314 | Mean IoU: 0.4166\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.1990 - mean_iou: 0.3528 - dice_coeff: 0.2798 - val_loss: 0.2730 - val_mean_iou: 0.3924 - val_dice_coeff: 0.2839 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1830 - mean_iou: 0.4216 - dice_coeff: 0.2844\n",
      "Epoch 4: val_mean_iou did not improve from 0.39235\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1518 | Mean IoU: 0.3517\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 0.1830 - mean_iou: 0.4216 - dice_coeff: 0.2844 - val_loss: 0.2521 - val_mean_iou: 0.3546 - val_dice_coeff: 0.2743 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1771 - mean_iou: 0.4376 - dice_coeff: 0.2864\n",
      "Epoch 5: val_mean_iou improved from 0.39235 to 0.39356, saving model to loss_experiments/model1_sparse_cce_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1326 | Mean IoU: 0.4188\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.1771 - mean_iou: 0.4376 - dice_coeff: 0.2864 - val_loss: 0.2989 - val_mean_iou: 0.3936 - val_dice_coeff: 0.2848 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1462 - mean_iou: 0.4830 - dice_coeff: 0.2932\n",
      "Epoch 6: val_mean_iou did not improve from 0.39356\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1419 | Mean IoU: 0.3880\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 0.1462 - mean_iou: 0.4830 - dice_coeff: 0.2932 - val_loss: 0.2519 - val_mean_iou: 0.3865 - val_dice_coeff: 0.2779 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1280 - mean_iou: 0.5042 - dice_coeff: 0.2960\n",
      "Epoch 7: val_mean_iou did not improve from 0.39356\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1121 | Mean IoU: 0.3742\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.1280 - mean_iou: 0.5042 - dice_coeff: 0.2960 - val_loss: 0.4072 - val_mean_iou: 0.3486 - val_dice_coeff: 0.2783 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1605 - mean_iou: 0.4598 - dice_coeff: 0.2898\n",
      "Epoch 8: val_mean_iou improved from 0.39356 to 0.40423, saving model to loss_experiments/model1_sparse_cce_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1344 | Mean IoU: 0.4345\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.1605 - mean_iou: 0.4598 - dice_coeff: 0.2898 - val_loss: 0.2598 - val_mean_iou: 0.4042 - val_dice_coeff: 0.2837 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1214 - mean_iou: 0.5162 - dice_coeff: 0.2977\n",
      "Epoch 9: val_mean_iou did not improve from 0.40423\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1285 | Mean IoU: 0.4077\n",
      "200/200 [==============================] - 48s 237ms/step - loss: 0.1214 - mean_iou: 0.5162 - dice_coeff: 0.2977 - val_loss: 0.3153 - val_mean_iou: 0.3920 - val_dice_coeff: 0.2841 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1201 - mean_iou: 0.5216 - dice_coeff: 0.2990\n",
      "Epoch 10: val_mean_iou improved from 0.40423 to 0.41694, saving model to loss_experiments/model1_sparse_cce_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1354 | Mean IoU: 0.4290\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.1201 - mean_iou: 0.5216 - dice_coeff: 0.2990 - val_loss: 0.2637 - val_mean_iou: 0.4169 - val_dice_coeff: 0.2846 - lr: 1.0000e-04\n",
      "\n",
      "======================================================================\n",
      "Training completed successfully!\n",
      "======================================================================\n",
      "\n",
      "Saving training history to saved_models/model1_sparse_cce_history.json...\n",
      "Exporting dynamics to saved_models/model1_sparse_cce_dynamics.json...\n",
      "Metrics exported to saved_models/model1_sparse_cce_dynamics.json\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING SUMMARY\n",
      "----------------------------------------------------------------------\n",
      "Model: model1\n",
      "Loss function: sparse_cce\n",
      "Best val_loss: 0.2264\n",
      "Best val_mean_iou: 0.4169\n",
      "\n",
      "Files saved:\n",
      "  - Model: loss_experiments/model1_sparse_cce_best.h5\n",
      "  - History: saved_models/model1_sparse_cce_history.json\n",
      "  - Dynamics: saved_models/model1_sparse_cce_dynamics.json\n",
      "  - Logs: logs/model1_sparse_cce\n",
      "\n",
      "View results in TensorBoard:\n",
      "  tensorboard --logdir=logs/\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Cleaning up memory...\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Training model1 with loss: weighted_cce\n",
      "======================================================================\n",
      "\n",
      "Building datasets...\n",
      "Training dataset batch size: 1\n",
      "Validation dataset batch size: 1\n",
      "\n",
      "Initializing optimized dynamics logger...\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0824 - mean_iou: 0.2045 - dice_coeff: 0.2169\n",
      "Epoch 1: val_mean_iou improved from -inf to 0.30856, saving model to loss_experiments/model1_weighted_cce_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1716 | Mean IoU: 0.2931\n",
      "200/200 [==============================] - 55s 252ms/step - loss: 0.0824 - mean_iou: 0.2045 - dice_coeff: 0.2169 - val_loss: 0.0765 - val_mean_iou: 0.3086 - val_dice_coeff: 0.2282 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0756 - mean_iou: 0.2070 - dice_coeff: 0.2211\n",
      "Epoch 2: val_mean_iou did not improve from 0.30856\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0726 | Mean IoU: 0.2871\n",
      "200/200 [==============================] - 50s 246ms/step - loss: 0.0756 - mean_iou: 0.2070 - dice_coeff: 0.2211 - val_loss: 0.0638 - val_mean_iou: 0.2512 - val_dice_coeff: 0.2389 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0634 - mean_iou: 0.2827 - dice_coeff: 0.2407\n",
      "Epoch 3: val_mean_iou did not improve from 0.30856\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0894 | Mean IoU: 0.3170\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 0.0634 - mean_iou: 0.2827 - dice_coeff: 0.2407 - val_loss: 0.0635 - val_mean_iou: 0.2587 - val_dice_coeff: 0.2486 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0525 - mean_iou: 0.3122 - dice_coeff: 0.2596\n",
      "Epoch 4: val_mean_iou improved from 0.30856 to 0.32278, saving model to loss_experiments/model1_weighted_cce_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1197 | Mean IoU: 0.3812\n",
      "200/200 [==============================] - 49s 240ms/step - loss: 0.0525 - mean_iou: 0.3122 - dice_coeff: 0.2596 - val_loss: 0.0626 - val_mean_iou: 0.3228 - val_dice_coeff: 0.2638 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0466 - mean_iou: 0.3408 - dice_coeff: 0.2687\n",
      "Epoch 5: val_mean_iou did not improve from 0.32278\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0798 | Mean IoU: 0.2991\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 0.0466 - mean_iou: 0.3408 - dice_coeff: 0.2687 - val_loss: 0.0665 - val_mean_iou: 0.2486 - val_dice_coeff: 0.2492 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0386 - mean_iou: 0.3730 - dice_coeff: 0.2805\n",
      "Epoch 6: val_mean_iou did not improve from 0.32278\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0817 | Mean IoU: 0.3162\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 0.0386 - mean_iou: 0.3730 - dice_coeff: 0.2805 - val_loss: 0.0756 - val_mean_iou: 0.2737 - val_dice_coeff: 0.2623 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0368 - mean_iou: 0.3842 - dice_coeff: 0.2837\n",
      "Epoch 7: val_mean_iou did not improve from 0.32278\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0662 | Mean IoU: 0.2828\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 0.0368 - mean_iou: 0.3842 - dice_coeff: 0.2837 - val_loss: 0.0603 - val_mean_iou: 0.2231 - val_dice_coeff: 0.2437 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0329 - mean_iou: 0.4109 - dice_coeff: 0.2873\n",
      "Epoch 8: val_mean_iou did not improve from 0.32278\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0837 | Mean IoU: 0.3196\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 0.0329 - mean_iou: 0.4109 - dice_coeff: 0.2873 - val_loss: 0.0680 - val_mean_iou: 0.2746 - val_dice_coeff: 0.2596 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0302 - mean_iou: 0.4270 - dice_coeff: 0.2913\n",
      "Epoch 9: val_mean_iou did not improve from 0.32278\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.0917 | Mean IoU: 0.3373\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 0.0302 - mean_iou: 0.4270 - dice_coeff: 0.2913 - val_loss: 0.0761 - val_mean_iou: 0.2896 - val_dice_coeff: 0.2648 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0288 - mean_iou: 0.4316 - dice_coeff: 0.2932\n",
      "Epoch 10: val_mean_iou did not improve from 0.32278\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1197 | Mean IoU: 0.3812\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 0.0288 - mean_iou: 0.4316 - dice_coeff: 0.2932 - val_loss: 0.0671 - val_mean_iou: 0.3071 - val_dice_coeff: 0.2699 - lr: 1.0000e-04\n",
      "Epoch 10: early stopping\n",
      "\n",
      "======================================================================\n",
      "Training completed successfully!\n",
      "======================================================================\n",
      "\n",
      "Saving training history to saved_models/model1_weighted_cce_history.json...\n",
      "Exporting dynamics to saved_models/model1_weighted_cce_dynamics.json...\n",
      "Metrics exported to saved_models/model1_weighted_cce_dynamics.json\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING SUMMARY\n",
      "----------------------------------------------------------------------\n",
      "Model: model1\n",
      "Loss function: weighted_cce\n",
      "Best val_loss: 0.0603\n",
      "Best val_mean_iou: 0.3228\n",
      "\n",
      "Files saved:\n",
      "  - Model: loss_experiments/model1_weighted_cce_best.h5\n",
      "  - History: saved_models/model1_weighted_cce_history.json\n",
      "  - Dynamics: saved_models/model1_weighted_cce_dynamics.json\n",
      "  - Logs: logs/model1_weighted_cce\n",
      "\n",
      "View results in TensorBoard:\n",
      "  tensorboard --logdir=logs/\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Cleaning up memory...\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Training model1 with loss: dice_loss\n",
      "======================================================================\n",
      "\n",
      "Building datasets...\n",
      "Training dataset batch size: 1\n",
      "Validation dataset batch size: 1\n",
      "\n",
      "Initializing optimized dynamics logger...\n",
      "Epoch 1/10\n",
      "  6/200 [..............................] - ETA: 44s - loss: 0.7898 - mean_iou: 0.2630 - dice_coeff: 0.2102WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1094s vs `on_train_batch_end` time: 0.1101s). Check your callbacks.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7333 - mean_iou: 0.3066 - dice_coeff: 0.2667\n",
      "Epoch 1: val_mean_iou improved from -inf to 0.30931, saving model to loss_experiments/model1_dice_loss_best.h5\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1726 | Mean IoU: 0.2938\n",
      "200/200 [==============================] - 53s 244ms/step - loss: 0.7333 - mean_iou: 0.3066 - dice_coeff: 0.2667 - val_loss: 0.7289 - val_mean_iou: 0.3093 - val_dice_coeff: 0.2711 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713\n",
      "Epoch 2: val_mean_iou did not improve from 0.30931\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1726 | Mean IoU: 0.2938\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713 - val_loss: 0.7289 - val_mean_iou: 0.3093 - val_dice_coeff: 0.2711 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713\n",
      "Epoch 3: val_mean_iou did not improve from 0.30931\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1726 | Mean IoU: 0.2938\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713 - val_loss: 0.7289 - val_mean_iou: 0.3093 - val_dice_coeff: 0.2711 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713\n",
      "Epoch 4: val_mean_iou did not improve from 0.30931\n",
      "\n",
      "  LR: 1.00e-04 | Class IoU Var: 0.1726 | Mean IoU: 0.2938\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713 - val_loss: 0.7289 - val_mean_iou: 0.3093 - val_dice_coeff: 0.2711 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713\n",
      "Epoch 5: val_mean_iou did not improve from 0.30931\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "  LR: 5.00e-05 | Class IoU Var: 0.1726 | Mean IoU: 0.2938\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713 - val_loss: 0.7289 - val_mean_iou: 0.3093 - val_dice_coeff: 0.2711 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713\n",
      "Epoch 6: val_mean_iou did not improve from 0.30931\n",
      "\n",
      "  LR: 5.00e-05 | Class IoU Var: 0.1726 | Mean IoU: 0.2938\n",
      "200/200 [==============================] - 47s 229ms/step - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713 - val_loss: 0.7289 - val_mean_iou: 0.3093 - val_dice_coeff: 0.2711 - lr: 5.0000e-05\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713\n",
      "Epoch 7: val_mean_iou did not improve from 0.30931\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "  LR: 5.00e-05 | Class IoU Var: 0.1726 | Mean IoU: 0.2938\n",
      "200/200 [==============================] - 47s 230ms/step - loss: 0.7287 - mean_iou: 0.3074 - dice_coeff: 0.2713 - val_loss: 0.7289 - val_mean_iou: 0.3093 - val_dice_coeff: 0.2711 - lr: 5.0000e-05\n",
      "Epoch 7: early stopping\n",
      "\n",
      "======================================================================\n",
      "Training completed successfully!\n",
      "======================================================================\n",
      "\n",
      "Saving training history to saved_models/model1_dice_loss_history.json...\n",
      "Exporting dynamics to saved_models/model1_dice_loss_dynamics.json...\n",
      "Metrics exported to saved_models/model1_dice_loss_dynamics.json\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING SUMMARY\n",
      "----------------------------------------------------------------------\n",
      "Model: model1\n",
      "Loss function: dice_loss\n",
      "Best val_loss: 0.7289\n",
      "Best val_mean_iou: 0.3093\n",
      "\n",
      "Files saved:\n",
      "  - Model: loss_experiments/model1_dice_loss_best.h5\n",
      "  - History: saved_models/model1_dice_loss_history.json\n",
      "  - Dynamics: saved_models/model1_dice_loss_dynamics.json\n",
      "  - Logs: logs/model1_dice_loss\n",
      "\n",
      "View results in TensorBoard:\n",
      "  tensorboard --logdir=logs/\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Cleaning up memory...\n",
      "\n",
      "======================================================================\n",
      "ALL EXPERIMENTS COMPLETED\n",
      "======================================================================\n",
      "\n",
      "To view all results in TensorBoard:\n",
      "  tensorboard --logdir=logs/\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "loss_functions = {\n",
    "    \"sparse_cce\": tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    \"weighted_cce\": weighted_cce,\n",
    "    \"dice_loss\": dice_loss,\n",
    "}\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"Convert numpy/tensorflow types to native Python types\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif hasattr(obj, 'numpy'):\n",
    "        return float(obj.numpy())\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "for loss_name, loss_function in loss_functions.items():\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    test_model_name = 'model1'\n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(f\"Training {test_model_name} with loss: {loss_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    log_dir = f'logs/{test_model_name}_{loss_name}'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    model = MODELS_REGISTRY[test_model_name]()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(config.LR),\n",
    "        loss=loss_function,\n",
    "        metrics=[\n",
    "            MeanIoUMetric(num_classes=3),\n",
    "            dice_coeff_metric()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"\\nBuilding datasets...\")\n",
    "    train_ds = build_dataset(\n",
    "        config.TRAIN_X,\n",
    "        config.TRAIN_Y,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        augment=True,\n",
    "        capped_size=200\n",
    "    )\n",
    "\n",
    "    val_ds = build_dataset(\n",
    "        config.VAL_X,\n",
    "        config.VAL_Y,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        capped_size=50\n",
    "    )\n",
    "    \n",
    "    print(f\"Training dataset batch size: {config.BATCH_SIZE}\")\n",
    "    print(f\"Validation dataset batch size: {config.BATCH_SIZE}\")\n",
    "\n",
    "    print(f\"\\nInitializing optimized dynamics logger...\")\n",
    "    dynamics_logger = OptimizedDynamicsLogger(\n",
    "        val_dataset=val_ds,\n",
    "        num_classes=3,\n",
    "        log_dir=log_dir,\n",
    "        max_samples=50,\n",
    "        batch_log_freq=100\n",
    "    )\n",
    "    cbs = [\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath=f\"saved_models/testing_loss/{test_model_name}_{loss_name}_best.h5\",\n",
    "            monitor=\"val_mean_iou\",\n",
    "            mode=\"max\",\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor=\"val_mean_iou\",\n",
    "            mode=\"max\",\n",
    "            patience=6,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            update_freq=50\n",
    "        ),\n",
    "        dynamics_logger\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=10,\n",
    "            callbacks=cbs,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"Training completed successfully!\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        history_path = f\"saved_models/testing_loss/{test_model_name}_{loss_name}_history.json\"\n",
    "        print(f\"\\nSaving training history to {history_path}...\")\n",
    "        with open(history_path, \"w\") as f:\n",
    "            serializable_history = convert_to_serializable(history.history)\n",
    "            json.dump(serializable_history, f, indent=2)\n",
    "\n",
    "        dyn_path = f\"saved_models/testing_loss/{test_model_name}_{loss_name}_dynamics.json\"\n",
    "        print(f\"Exporting dynamics to {dyn_path}...\")\n",
    "        dynamics_logger.export_to_json(dyn_path)\n",
    "\n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\"TRAINING SUMMARY\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"Model: {test_model_name}\")\n",
    "        print(f\"Loss function: {loss_name}\")\n",
    "        print(f\"Best val_loss: {min(history.history['val_loss']):.4f}\")\n",
    "        if 'mean_iou' in history.history:\n",
    "            print(f\"Best val_mean_iou: {max(history.history.get('val_mean_iou', [0])):.4f}\")\n",
    "        print(f\"\\nFiles saved:\")\n",
    "        print(f\"  - Model: saved_models/testing_loss/{test_model_name}_{loss_name}_best.h5\")\n",
    "        print(f\"  - History: {history_path}\")\n",
    "        print(f\"  - Dynamics: {dyn_path}\")\n",
    "        print(f\"  - Logs: {log_dir}\")\n",
    "        print(\"\\nView results in TensorBoard:\")\n",
    "        print(f\"  tensorboard --logdir=logs/\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n{'!'*70}\")\n",
    "        print(f\"ERROR during training with {loss_name}\")\n",
    "        print(f\"{'!'*70}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    finally:\n",
    "        print(\"\\nCleaning up memory...\")\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL EXPERIMENTS COMPLETED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTo view all results in TensorBoard:\")\n",
    "print(\"  tensorboard --logdir=logs/loss/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
